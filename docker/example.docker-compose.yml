version: '2'
services:
  # This has 2 ElasticSearch nodes. Scale as necessary to additional nodes.
  elasticsearch:
      image: docker.elastic.co/elasticsearch/elasticsearch-oss:7.9.2
      container_name: elasticsearch
      logging:
          driver: json-file
          options:
              max-size: ${DOCKER_LOG_MAX_SIZE}
              max-file: ${DOCKER_LOG_MAX_FILE}
      ulimits:
        memlock:
          soft: -1
          hard: -1
      # This value is suitable for dev. Set higher for production.
      mem_limit: ${ES_MEM_LIMIT}
      ports:
          - 9200:9200
      volumes:
        - ${TWEETSETS_DATA_PATH}/elasticsearch/esdata1:/usr/share/elasticsearch/data
      networks:
        - tweetsets
      environment:
        - cluster.name=${CLUSTER_NAME}
        - bootstrap.memory_lock=true
        - "ES_JAVA_OPTS=-Xms${ES_JAVA_MEM} -Xmx${ES_JAVA_MEM}"
        - TZ
        # added for 7.9.2
        - node.name=elasticsearch
        - cluster.initial_master_nodes=elasticsearch,elasticsearch2
      restart: always
  elasticsearch2:
      image: docker.elastic.co/elasticsearch/elasticsearch-oss:7.9.2
      container_name: elasticsearch2
      logging:
          driver: json-file
          options:
              max-size: ${DOCKER_LOG_MAX_SIZE}
              max-file: ${DOCKER_LOG_MAX_FILE}
      ulimits:
        memlock:
          soft: -1
          hard: -1
      # This value is suitable for dev. Set higher for production.
      mem_limit: ${ES_MEM_LIMIT}
      volumes:
        - ${TWEETSETS_DATA_PATH}/elasticsearch/esdata2:/usr/share/elasticsearch/data
      networks:
        - tweetsets
      environment:
        - cluster.name=${CLUSTER_NAME}
        - bootstrap.memory_lock=true
        - "ES_JAVA_OPTS=-Xms${ES_JAVA_MEM} -Xmx${ES_JAVA_MEM}"
        - "discovery.zen.ping.unicast.hosts=elasticsearch"
        - TZ
        # added for 7.9.2
        - node.name=elasticsearch2
        - cluster.initial_master_nodes=elasticsearch,elasticsearch2
      restart: always
  redis:
      image: redis:4.0.8
      logging:
          driver: json-file
          options:
              max-size: ${DOCKER_LOG_MAX_SIZE}
              max-file: ${DOCKER_LOG_MAX_FILE}
      command: --appendonly yes
      volumes:
          - ${TWEETSETS_DATA_PATH}/redis:/data
      networks:
        - tweetsets
      environment:
       - TZ
      restart: always
  # For production
  server:
      image: gwul/tweetsets-server
#      build:
#          context: ..
#          dockerfile: Dockerfile-server
      logging:
          driver: json-file
          options:
              max-size: ${DOCKER_LOG_MAX_SIZE}
              max-file: ${DOCKER_LOG_MAX_FILE}
      links:
        - redis:redis
        - elasticsearch:elasticsearch
      ports:
          - ${SERVER_PORT}:8080
      volumes:
        - ${TWEETSETS_DATA_PATH}/datasets:/tweetsets_data/datasets
        - ${TWEETSETS_DATA_PATH}/extracts:/tweetsets_data/extracts
        # Link in a file containing a message to be displayed on dataset list page, e.g., for other
        # collections that are available, but not loaded.
        - "./dataset_list_msg.txt:/opt/tweetsets/dataset_list_msg.txt"
      networks:
        - tweetsets
      environment:
        - SECRET_KEY=${SERVER_SECRET_KEY}
        - TZ
        - SERVER_MODE
        - IP_RANGE
        # For ngninx-proxy
        - VIRTUAL_HOST=${HOSTNAME}
        - VIRTUAL_PORT=${SERVER_PORT}
        # For email
        - EMAIL_PORT
        - EMAIL_SMTP
        - EMAIL_FROM
        - EMAIL_USERNAME
        - EMAIL_PASSWORD
        - ADMIN_EMAIL
        - USE_TLS
        - HOST=${HOSTNAME}
        - ES_TIMEOUT
        - SERVER_TIMEOUT
        - CONSENT_HTML
        - CONSENT_BUTTON_TEXT
      restart: always
  # For development
#  server-flaskrun:
      image: gwul/tweetsets-flaskrun
##      build:
##          context: ..
##          dockerfile: Dockerfile-flaskrun
#      logging:
#          driver: json-file
#          options:
#              max-size: ${DOCKER_LOG_MAX_SIZE}
#              max-file: ${DOCKER_LOG_MAX_FILE}
#      links:
#        - redis:redis
#        - elasticsearch:elasticsearch
#      ports:
#          - ${SERVER_PORT}:5000
#      volumes:
#        - /tweetsets_data/datasets:/tweetsets_data/datasets
#        - /tweetsets_data/datasets:/tweetsets_data/datasets
#        # Link in a file containing a message to be displayed on dataset list page, e.g., for other
#        # collections that are available, but not loaded.
#        - "./dataset_list_msg.txt:/opt/tweetsets/dataset_list_msg.txt"
#        # This links in external code.
#        - "..:/opt/tweetsets"
#      networks:
#        - tweetsets
#      environment:
#        - SECRET_KEY=${SERVER_SECRET_KEY}
#        - TZ
#        - SERVER_MODE
#        - IP_RANGE
#        - ES_TIMEOUT
#        - CONSENT_HTML
#        - CONSENT_BUTTON_TEXT
  worker:
      image: gwul/tweetsets-worker
#      build:
#          context: ..
#          dockerfile: Dockerfile-worker
      logging:
          driver: json-file
          options:
              max-size: ${DOCKER_LOG_MAX_SIZE}
              max-file: ${DOCKER_LOG_MAX_FILE}
      links:
        - redis:redis
        - elasticsearch:elasticsearch
      volumes:
        - ${TWEETSETS_DATA_PATH}/datasets:/tweetsets_data/datasets
        - ${TWEETSETS_DATA_PATH}/extracts:/tweetsets_data/extracts
      networks:
        - tweetsets
      environment:
        - LOGGING_LEVEL=${WORKER_LOGGING_LEVEL}
        - TZ
        - ES_TIMEOUT
        - EMAIL_PORT
        - EMAIL_SMTP
        - EMAIL_FROM
        - EMAIL_USERNAME
        - EMAIL_PASSWORD
        - ADMIN_EMAIL
        - USE_TLS
      restart: always
  # This will exit. That's OK.
  loader:
      image: gwul/tweetsets-loader
#      build:
#          context: ..
#          dockerfile: Dockerfile-loader
      logging:
          driver: json-file
          options:
              max-size: ${DOCKER_LOG_MAX_SIZE}
              max-file: ${DOCKER_LOG_MAX_FILE}
      links:
        - elasticsearch:elasticsearch
        - elasticsearch2:elasticsearch2
        - spark-master
      volumes:
        - ${DATASET_PATH}:/dataset
      networks:
        - tweetsets
      environment:
        - TZ
        - STORE_TWEET
#    # For running with HTTPS
#    # When using this set SERVER_PORT in .env to 8080. Also, make sure HOSTNAME is set correctly.
#    # For more information on configuration of nginx-proxy, see https://github.com/jwilder/nginx-proxy
#  nginx-proxy:
#      image: jwilder/nginx-proxy
#      logging:
#          driver: json-file
#          options:
#              max-size: ${DOCKER_LOG_MAX_SIZE}
#              max-file: ${DOCKER_LOG_MAX_FILE}
#      ports:
#        - "443:443"
#        - "80:80"
#      networks:
#        - tweetsets
#      environment:
#        - DEFAULT_HOST=${HOSTNAME}
#      volumes:
#        - /var/run/docker.sock:/tmp/docker.sock:ro
#        # This should point to your local key and certificate
#        # Make sure in the cert that the server cert comes before the intermediate certs.
#        - "./server.crt:/etc/nginx/certs/${HOSTNAME}.crt"
#        - "./server.key:/etc/nginx/certs/${HOSTNAME}.key"
#        # To include a custom configuration file for nginx, e.g., to increase proxy timeout.
#        # See example.vhost.conf.
#        - "./vhost.conf:/etc/nginx/vhost.d/${HOSTNAME}"
#      restart: always
#  kibana:
#      image: docker.elastic.co/kibana/kibana-oss:6.2.2
#      logging:
#          driver: json-file
#          options:
#              max-size: ${DOCKER_LOG_MAX_SIZE}
#              max-file: ${DOCKER_LOG_MAX_FILE}
#      ports:
#        - 5601:5601
#      networks:
#        - tweetsets
#      environment:
#        - TZ
#      restart: always
networks:
  tweetsets:
